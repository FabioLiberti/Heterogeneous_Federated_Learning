# HFEDL
Heterogeneous Federated Learning (Research)


https://www.sciencedirect.com/science/article/abs/pii/S138650561830008X
https://pubmed.ncbi.nlm.nih.gov/29500022/


Hetergeneous Federated Learning
Heterogeneous Federated Learning: State-of-the-art and Research Challenges (Accepted to ACM Computing Surveys)
Mang Ye, Xiuwen Fang, Bo Du, Pong C. Yuen, Dacheng Tao

Survey for Hetergeneous Federated Learning by MARS Group at the Wuhan University, led by Prof. Mang Ye.

contributions welcome

Table of Contents

Our Works
Federated Learning with Domain Shift
Federated Learning with Heterogeneous Graph
Federated Learning with Data Noise
Federated Learning with Few-Shot
HFL Survey
Research Challenges
Statistical Heterogeneity
Model Heterogeneity
Communication Heterogeneity
Device Heterogeneity
Additional Challenges
State-Of-The-Art(Updating)
Data-Level
Model-Level
Server-Level
Future Direction(Updating)
Improving Communication Efficiency
Federated Fairness
Privacy Protection
Attack Robustness
Uniform Benchmark
Our Works
Federated Learning with Domain Shift
FPL — Rethinking Federated Learning with Domain Shift: A Prototype View CVPR 2023 [Code]

We handle federated learning with domain shift from the prototype view.

FCCL — Learn from Others and Be Yourself in Heterogeneous Federated Learning CVPR 2022 [Code]

We investigate heterogeneity problems and catastrophic forgetting in federated learning.

Federated Learning with Heterogeneous Graph
FGSSL — Federated Graph Semantic and Structural Learning IJCAI 2023 [Code]

We handle federated graph learning from node-level semantic and graph-level structure.

Federated Learning with Data Noise
RHFL — Robust Federated Learning With Noisy and Heterogeneous Clients CVPR 2022 [Code]

We deal with robust federated learning with noisy and heterogeneous clients.

AugHFL — Robust Heterogeneous Federated Learning under Data Corruption ICCV 2023 (Coming soon)

We deal with robust heterogeneous federated learning under data corruption.

Federated Learning with Few-Shot
FSMAFL — Few-Shot Model Agnostic Federated Learning ACMMM 2022 [Code]

We study a challenging problem, namely few-shot model agnostic federated learning.

HFL Survey
Overview
Overview

Research Challenges
Statistical Heterogeneity
Statistical heterogeneity refers to the case where the data distribution across clients in federated learning is inconsistent and does not obey the same sampling, i.e., Non-IID.

Statistical Heterogeneity

Model Heterogeneity
Model heterogeneity refers to the fact that in federated learning, participating clients may have local models with different architectures.

Communication Heterogeneity
The devices are typically deployed in different network environments and have different network connectivity settings (3G, 4G, 5G, Wi-Fi), which leads to inconsistent communication bandwidth, latency, and reliability, i.e., communication heterogeneity.

Device Heterogeneity
The differences in device hardware capabilities (CPU, memory, battery life) may lead to different storage and computation capabilities, which inevitably lead to device heterogeneity.

Additional Challenges
Knowledge Transfer Barrier

Federated learning aims to transfer knowledge among different clients to collaboratively learn models with superior performance. However, the four heterogeneities mentioned above will cause knowledge transfer barriers.

Privacy Leakage

Federated learning by itself cannot guarantee perfect data security, as there are still potential privacy risks. Moreover, the above-mentioned four types of heterogeneity inevitably exacerbate privacy leakage in different learning stages.

State-Of-The-Art
Data-Level
Private Data Processing

Data Preparation
Safe — Safe: Synergic Data Filtering for Federated Learning in Cloud-Edge Computing IEEE TII 2022

Safe detects and filters out poisoned data from attacked devices through a clustering algorithm.

FedMix — FedMix: Approximation of Mixup under Mean Augmented Federated Learning ICLR 2021

FedMix performs data augmentation based on the MixUp strategy.

Astraea — Astraea: Self-Balancing Federated Learning for Improving Classification Accuracy of Mobile Deep Learning Applications ICCD 2019

Astraea performs data augmentation based on the global data distribution, generated by collecting the local data distribution.

FAug — Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data NeurIPS 2018 Workshop

FAug studies the trade-off between privacy leakage and communication overhead through a GAN-based data augmentation scheme.

Data Privacy Protection
PLDP-PFL — Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data IEEE IoT 2020

PLDP-PFL performs personalized differential privacy according to the sensitivity of private data.

A Syntactic Approach for Privacy in FL — Anonymizing Data for Privacy-Preserving Federated Learning

They use anonymization technology to desensitize local private data.

External Data Utilization

Knowledge Distillation
Unsupervised Representation Learning
Model-Level
Federated Optimization

Regularization

Meta Learning

Multi-task Learning

Knowledge Transfer

Knowledge Distillation

Transfer Learning

Architecture Sharing

Backbone Sharing

Classifier Sharing

Other Part Sharing

Server-Level
Client Selection
Client Clustering
Decentralized Communication
Future Direction
Improving Communication Efficiency
Federated Fairness
Privacy Protection
Attack Robustness
Attack Methods
DBA — DBA: Distributed Backdoor Attacks against Federated Learning ICLR 2020
DBA strategy decomposes a global trigger into local triggers, and injects them into multiple malicious clients.

Edge-case backdoors — Attack of the Tails: Yes, You Really Can Backdoor Federated Learning NeurIPS 2020
Edge-case backdoors consider poisoning edge-case samples (the tail data of the data distributions).

Defense strategies
CRFL — CRFL: Certifiably Robust Federated Learning against Backdoor Attacks ICML 2021
CRFL improves the robustness against backdoor attacks by clipping the model and adding smooth noise.

RBML-DFL — A Blockchain-based Multi-layer Decentralized Framework for Robust Federated Learning IJCNN 2022
RBML-DFL can prevent central server failures or malfunctions through blockchain encrypted transactions.

ResSFL — ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning CVPR 2022
ResSFL is trained by experts through attacker perception to obtain a resistant feature extractor that can initialize the client models.

Soteria — Soteria: Provable Defense against Privacy Leakage in Federated Learning from Representation Perspective
Soteria performs attack defense by generating perturbed data representations, thereby decreasing the quality of reconstructed data.

BaFFLe — BaFFLe: Backdoor Detection via Feedback-based Federated Learning
The server trains backdoor filters and sends them randomly to clients to identify and remove backdoor instances.

Uniform Benchmark
General Federated Learning Systems
FedML — FedML: A Research Library and Benchmark for Federated Machine Learning
FedML is an research library that supports distributed training, mobile on-device training, and stand-alone simulation training. It provides standardized implementations of many existing federated learning algorithms, and provides standardized benchmark settings for a variety of datasets, including Non-IID partition methods, number of devices and baseline models.

FedScale — FedScale: Benchmarking Model and System Performance of Federated Learning at Scale ICML 2022
FedScale is a federated learning benchmark suite that provides real-world datasets covering a wide range of federated learning tasks, including image classification, object detection, language modeling, and speech recognition. Additionally, FedScale includes a scalable and extensible FedScale Runtime to enable and standardize real-world end-point deployments of federated learning.

OARF — The OARF Benchmark Suite: Characterization and Implications for Federated Learning Systems ACM TIST 2020
OARF leverages public datasets collected from different sources to simulate real-world data distributions. In addition, OARF quantitatively studies the preliminary relationship among various design metrics such as data partitioning and privacy mechanisms in federated learning systems.

FedEval — FedEval: A Holistic Evaluation Framework for Federated Learning
FedEval is a federated learning evaluation model with five metrics including accuracy, communication, time consumption, privacy and robustness. FedEval is implemented and evaluated on two of the most widely used algorithms, FedSGD and FedAvg.

Specific Federated Learning Systems
FedReIDBench — Performance Optimization of Federated Person Re-identification via Benchmark Analysis ACM MM 2020
FedReIDBench is a new benchmark for implementing federated learning to person ReID, which includes nine different datasets and two federated scenarios. Specifically, the two federated scenarios are federated-by-camera scenario and federated-by-dataset scenario, which respectively represent the standard server-client architecture and client-edge-cloud architecture.

pFL-Bench — pFL-Bench: A Comprehensive Benchmark for Personalized Federated Learning NeurIPS 2022 Datasets and Benchmarks Track
pFL-Bench is a benchmark for personalized federated learning, which covers twelve different dataset variants, including image, text, graph and recommendation data, with unified data partitioning and realistic heterogeneous settings. And pFL-Bench provides more than 20 competitive personalized federated learning baseline implementations to help them with standardized evaluation.

FedGraphNN — FedGraphNN: A Federated Learning System and Benchmark for Graph Neural Networks ICLR 2021 Workshop on DPML
FedGraphNN is a benchmark system built on a unified formulation of graph federated learning, including extensive datasets from seven different fields, popular Graph Neural Network (GNN) models and federated learning algorithms.

Datasets
LEAF — LEAF: A Benchmark for Federated Settings NeurIPS 2019 Workshop
LEAF contains 6 types of federated datasets covering different fields, including image classification (FEMNIST, Synthetic Dataset), image recognition (Celeba), sentiment analysis (Sentiment140) and next character prediction (Shakespeare, Reddit). In addition, LEAF provides two sampling methods of 'IID' and 'Non-IID' to divide the dataset to different clients.

Street Dataset — Real-World Image Datasets for Federated Learning FL-NeurIPS 2019
This work introduces a federated dataset for object detection. The dataset contains over 900 images generated from 26 street cameras and 7 object categories annotated with detailed bounding boxes. Besides, the article provides the data division of 5 or 20 clients, in which their data distribution is Non-IID and unbalanced, reflecting the characteristics of real-world federated learning scenarios.
